# [WIP] Dockerizando a nossa aplicação e introduzindo o PostgreSQL

---
Objetivos da aula:

- Compreender os conceitos básicos do Docker
- Aprender o que é um Dockerfile e sua estrutura
- Entender como criar uma imagem Docker para a nossa aplicação FastAPI
- Aprender a rodar a aplicação utilizando Docker
- Introduzir o conceito de Docker Compose para gerenciamento de múltiplos contêineres
- Entender os benefícios e motivos da mudança de SQLite para PostgreSQL

??? tip "Caso prefira ver a aula em vídeo"
	![type:video](https://www.youtube.com/embed/u31qwQUeGuM)

[Aula :fontawesome-brands-youtube:](#){ .md-button }
[Slides :fontawesome-solid-file-powerpoint:](#){ .md-button }
[Código :fontawesome-solid-code:](https://github.com/dunossauro/fastapi-do-zero/tree/main/codigo_das_aulas/08/){ .md-button }

---

Depois de implementar nosso gerenciador de tarefas na aula anterior, temos uma versão estável da nossa aplicação. Nesta aula, além de aprendermos a "dockerizar" nossa aplicação FastAPI, também abordaremos a migração do banco de dados SQLite para o PostgreSQL.


## O Docker

Docker é uma plataforma aberta que permite automatizar o processo de implantação, escalonamento e operação de aplicações dentro de contêineres. Ele serve para "empacotar" uma aplicação e suas dependências em um contêiner virtual que pode ser executado em qualquer sistema operacional que suporte Docker. Isso facilita a implantação, o desenvolvimento e o compartilhamento de aplicações, além de proporcionar um ambiente isolado e consistente.

## Criando nosso Dockerfile

O Dockerfile é um arquivo de texto que contém todas as instruções para construir uma imagem Docker. Ele define o ambiente de execução, os comandos necessários para preparar o ambiente e o comando a ser executado quando um contêiner é iniciado a partir da imagem.

Aqui está o nosso Dockerfile para a aplicação FastAPI:

```docker
FROM python:3.11-slim
ENV POETRY_VIRTUALENVS_CREATE=false

RUN pip install poetry

COPY . .

RUN poetry config installer.max-workers 10
RUN poetry install --no-interaction --no-ansi

EXPOSE 8000
CMD [ "poetry", "run", "uvicorn", "--host", "0.0.0.0", "fast_zero.app:app" ]
```

Aqui está o que cada linha faz:

1. `FROM python:3.11-slim`: Define a imagem base para nosso contêiner. Estamos usando a versão slim da imagem do Python 3.11, que tem tudo que precisamos para rodar nossa aplicação.
2. `ENV POETRY_VIRTUALENVS_CREATE=false`: Define uma variável de ambiente que diz ao Poetry para não criar um ambiente virtual.
3. `RUN pip install poetry`: Instala o Poetry, nosso gerenciador de pacotes.
4. `COPY . .`: Copia todos os arquivos do diretório atual para o contêiner.
5. `RUN poetry config installer.max-workers 10`: Configura o Poetry para usar até 10 workers ao instalar pacotes.
6. `RUN poetry install --no-interaction --no-ansi`: Instala as dependências do nosso projeto sem interação e sem cores no output.
7. `EXPOSE 8000`: Informa ao Docker que o contêiner vai escutar na porta 8000.
8. `CMD [ "poetry", "run", "uvicorn", "--host", "0.0.0.0", "fast_zero.app:app" ]`: Define o comando que será executado quando o contêiner for iniciado.

Vamos entender melhor esse último comando:

- `poetry run` define o comando que será executado dentro do ambiente virtual criado pelo Poetry.
- `uvicorn` é o servidor ASGI que usamos para rodar nossa aplicação.
- `--host` define o host que o servidor vai escutar. Especificamente, `"0.0.0.0"` é um endereço IP que permite que o servidor aceite conexões de qualquer endereço de rede disponível, tornando-o acessível externamente.
- `fast_zero.app:app` define o `<módulo python>:<objeto>` que o servidor vai executar.


## Criando a imagem

Para criar uma imagem Docker a partir do Dockerfile, usamos o comando `docker build`. O comando a seguir cria uma imagem chamada "fast_zero":

```shell title="$ Execução no terminal!"
docker build -t "fast_zero" .
```

Este comando lê o Dockerfile no diretório atual (indicado pelo `.`) e cria uma imagem com a tag "fast_zero", (indicada pelo `-t`).

Vamos então verificar se a imagem foi criada com sucesso usando o comando:

```shell title="$ Execução no terminal!"
docker images
```

Este comando lista todas as imagens Docker disponíveis no seu sistema.
## Rodando o container

Para rodar o contêiner, usamos o comando `docker run`. Especificamos o nome do contêiner com a flag `--name`, indicamos a imagem que queremos executar e a tag que queremos usar `<nome_da_imagem>:<tag>`. A flag `-p` serve para mapear a porta do host para a porta do contêiner `<porta_do_host>:<porta_do_contêiner>`. Portanto, teremos o seguinte comando:

```shell title="$ Execução no terminal!"
docker run --name fastzeroapp -p 8000:8000 fast_zero:latest
```

Este comando iniciará nossa aplicação dentro de um contêiner Docker, que estará escutando na porta 8000. Para testar se tudo está funcionando corretamente, você pode acessar `http://localhost:8000` em um navegador ou usar um comando como:

```shell title="$ Execução no terminal!"
curl http://localhost:8000
```

## Gerenciando Containers

Depois de executar e testar a aplicação, é uma boa prática saber como parar e remover contêineres. Isto é especialmente útil durante o desenvolvimento, para manter o ambiente limpo:

1. **Parar um contêiner**: 
   
   ```shell title="$ Execução no terminal!"
   docker stop fastzeroapp
   ```

2. **Remover um contêiner**:

   ```shell title="$ Execução no terminal!"
   docker rm fastzeroapp
   ```

Ambos os comandos usam o nome do contêiner que definimos anteriormente com a flag `--name`.

## Introduzindo o postgreSQL

O [PostgreSQL](https://www.postgresql.org/) é um sistema de gerenciamento de banco de dados objeto-relacional (ORDBMS) poderoso e de código aberto. Ele é amplamente utilizado em produção em muitas empresas devido à sua robustez, escalabilidade e conjunto de recursos extensos.

Mudar para um banco de dados como PostgreSQL tem vários benefícios:

- **Escalabilidade**: SQLite não é ideal para aplicações em larga escala ou com grande volume de dados. PostgreSQL foi projetado para lidar com uma grande quantidade de dados e requisições.
- **Concorrência**: Diferentemente do SQLite, que tem limitações para gravações simultâneas, o PostgreSQL suporta múltiplas operações simultâneas.
- **Funcionalidades avançadas**: PostgreSQL vem com várias extensões e funcionalidades que o SQLite pode não oferecer.

Além disso, SQLite tem algumas limitações que podem torná-lo inadequado para produção em alguns casos. Por exemplo, ele não suporta alta concorrência e pode ter problemas de performance com grandes volumes de dados.

!!! note "Nota"
	Embora para o escopo da nossa aplicação e os objetivos de aprendizado o SQLite pudesse ser suficiente, é sempre bom nos prepararmos para cenários de produção real. A adoção de PostgreSQL nos dá uma prévia das práticas do mundo real e garante que nossa aplicação possa escalar sem grandes modificações de infraestrutura.

### Como executar o postgres?

Embora o PostgreSQL seja poderoso, sua instalação direta em uma máquina real pode ser desafiadora e pode resultar em configurações diferentes entre os ambientes de desenvolvimento. Felizmente, podemos utilizar o Docker para resolver esse problema. Existem imagens pré-construídas do PostgreSQL disponíveis no Docker Hub, que nos permitem executar o PostgreSQL com um único comando. Confira a [imagem oficial do PostgreSQL](https://hub.docker.com/_/postgres).

Para executar um contêiner do PostgreSQL, use o seguinte comando:

```shell title="$ Execução no terminal!"
docker run -d \
    --name app_database \
    -e POSTGRES_USER=app_user \
    -e POSTGRES_DB=app_db \
    -e POSTGRES_PASSWORD=app_password \
    postgres
```

!!! warning "Sobre as variáveis"
	
	Os valores acima (`app_user`, `app_db`, e `app_password`) são padrões genéricos para facilitar a inicialização do PostgreSQL em um ambiente de desenvolvimento. No entanto, é altamente recomendável que você altere esses valores, especialmente `app_password`, para garantir a segurança do seu banco de dados.

Explicação: Aqui estamos fornecendo algumas variáveis de ambiente para configurar nossa instância do PostgreSQL. Elas incluem nome de usuário, banco de dados e senha.

Agora, vamos falar sobre volumes. Um volume é utilizado para persistir os dados entre as execuções do contêiner. Ele é crucial para garantir que os dados no banco de dados não sejam perdidos quando o contêiner é parado.

```shell title="$ Execução no terminal!"
docker run -d \
    --name app_database \
    -e POSTGRES_USER=app_user \
    -e POSTGRES_DB=app_db \
    -e POSTGRES_PASSWORD=app_password \
    -v pgdata:/var/lib/postgresql/data \
    postgres
```

Neste comando, o `-v pgdata:/var/lib/postgresql/data` cria um volume chamado "pgdata", que, em sua máquina host, será um diretório no local onde você executou o comando do contêiner. Esse diretório mapeia para o diretório `/var/lib/postgresql/data` no contêiner. Este é o diretório onde o PostgreSQL armazena seus dados.

### Adicionando o suporte ao PostgreSQL na nossa aplicação

Para que o SQLAlchemy suporte o PostgreSQL, precisamos instalar uma dependência chamada `psycopg2-binary`. Este é o adaptador PostgreSQL para Python e é crucial para fazer a comunicação.

Para adicionar suporte ao PostgreSQL, execute:

```bash
poetry add psycopg2-binary
```

Com o SQLAlchemy sendo um ORM, a beleza é que, com algumas pequenas alterações, como a string de conexão, podemos mudar facilmente o backend do banco de dados. Portanto, após atualizar o arquivo `.env` com a nova string de conexão do PostgreSQL, nossa aplicação deve continuar funcionando como antes, mas agora usando o PostgreSQL.

Para configurar a conexão com o PostgreSQL, atualize seu arquivo `.env` com as seguintes variáveis de ambiente:

```bash title=".env"
DATABASE_URL=postgresql://app_user:app_password@localhost:5432/app_db
```

!!! error "Caso tenha alterado as variáveis de ambiente do container"

	Substitua `app_user`, `app_password`, e `app_db` pelos valores definidos anteriormente ao criar o contêiner PostgreSQL. Além disso, `localhost` é usado aqui para representar que o banco de dados PostgreSQL está sendo executado na mesma máquina. Se estiver em um host diferente, substitua `localhost` pelo endereço IP apropriado e ajuste a porta `5432` se necessário.


### Executando as migrações

Migrações são como versões para seu banco de dados, permitindo que você atualize sua estrutura de forma ordenada e controlada. Sempre que mudamos de banco de dados, ou até mesmo quando alteramos sua estrutura, as migrações precisam ser executadas para garantir que a base de dados esteja em sincronia com nosso código.

No contexto de contêineres, rodar as migrações se torna ainda mais simples. Quando mudamos de banco de dados, como é o caso de termos saído de um SQLite (por exemplo) para um PostgreSQL, as migrações são essenciais. O motivo é simples: o novo banco de dados não terá a estrutura e os dados do antigo, a menos que migremos. As migrações irão garantir que o novo banco de dados tenha a mesma estrutura e relações que o anterior.

Para rodar as migrações usando containers, geralmente temos um comando associado ao nosso serviço de aplicação que permite essa execução. Vamos ver como fazer isso:

```bash
docker exec -it fastzeroapp poetry run alembic upgrade head
```

O comando `docker exec` é utilizado para executar um comando específico em um contêiner que já está rodando. O parâmetro `-it` é uma combinação de dois parâmetros: `-i` (interativo) e `-t` (pseudo-TTY). Juntos, eles fazem com que o terminal onde o comando está sendo executado seja interativo, ou seja, permite que você interaja diretamente com o contêiner.


Lembrando que, após a execução, seu novo banco de dados PostgreSQL estará em sincronia com as definições de sua aplicação, pronto para ser usado como se fosse o antigo banco de dados!

### Executando a aplicação e o banco de dados

Ao trabalhar com múltiplos contêineres, especialmente em ambientes de desenvolvimento, pode se tornar um pouco trabalhoso gerenciar todos eles individualmente. Antes do advento de soluções como o Docker Compose, a abordagem padrão era iniciar cada contêiner separadamente e garantir que eles pudessem se comunicar. Vamos demonstrar essa abordagem:

1. **Executando o PostgreSQL**:

	Primeiro, iniciamos nosso banco de dados PostgreSQL:

	```bash
	docker run -d \
		--name fastzero_database \
		-e POSTGRES_USER=fastzero_user \
		-e POSTGRES_DB=fastzero_db \
		-e POSTGRES_PASSWORD=secure_password \
		-v pgdata:/var/lib/postgresql/data \
		postgres
	```

2. **Executando a aplicação**:

	Assumindo que você tenha uma imagem Docker para sua aplicação chamada `fastzero_app`, você pode executá-la da seguinte forma:

	```bash
	docker run -d \
		--name fastzero_app_instance \
		--link fastzero_database:database \
		fastzero_app
	```

Aqui, usamos o `--link` para criar uma conexão entre a nossa aplicação e o banco de dados, permitindo que nossa aplicação se comunique com o banco de dados usando o nome "database".

Após iniciar ambos os contêineres, a aplicação tentará se conectar ao banco de dados usando o nome "database" como o hostname do banco de dados na sua string de conexão.

!!! warning "Possíveis problemas"
	
	Embora este método funcione, ele tem limitações. Por exemplo, se tivéssemos vários serviços ou se quiséssemos gerenciar redes Docker personalizadas, a abordagem se tornaria complicada. Além disso, o uso do `--link` é considerado obsoleto e pode ser removido em versões futuras do Docker. É aqui que soluções como o Docker Compose entram em jogo, simplificando o gerenciamento e a comunicação entre contêineres. Com o Docker Compose, podemos definir todos os nossos serviços em um único arquivo e gerenciá-los coletivamente, eliminando muitos dos desafios da abordagem manual.

## Simplificando nosso fluxo com `docker-compose`

Docker Compose é uma ferramenta que permite definir e gerenciar aplicativos multi-contêiner com Docker. **Em termos simples, é como se você tivesse um maestro conduzindo uma orquestra: em vez de ter que dirigir cada músico (ou contêiner) individualmente, o maestro (ou Docker Compose) garante que todos toquem em harmonia.** Em vez de gerenciar individualmente cada contêiner (como nossa aplicação e o PostgreSQL), podemos definir ambos em um único arquivo `docker-compose.yml` e gerenciá-los simultaneamente com comandos simples.

Ao usar o Docker Compose, nosso objetivo é simplificar o processo de desenvolvimento, tornando mais fácil rodar nossa aplicação e seus serviços dependentes com um único comando.

### Criação do `docker-compose.yml`

```yaml
version: '3'

services:
  fastzero_database:
    image: postgres
    volumes:
      - pgdata:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: fastzero_user
      POSTGRES_DB: fastzero_db
      POSTGRES_PASSWORD: secure_password

  fastzero_app:
    image: fastzero_app
    ports:
      - "8000:8000"
    depends_on:
      - fastzero_database
    environment:
      DATABASE_URL: postgresql://fastzero_user:secure_password@fastzero_database/fastzero_db

volumes:
  pgdata:
```


**Explicação linha a linha:**

1. `version: '3'`: Especifica a versão do formato do arquivo Compose. O número '3' é uma das versões mais recentes e amplamente usadas.

2. `services:`: Define os serviços (contêineres) que serão gerenciados.

3. `fastzero_database:`: Define nosso serviço de banco de dados PostgreSQL.

4. `image: postgres`: Usa a imagem oficial do PostgreSQL.

5. `volumes:`: Mapeia volumes para persistência de dados.

   - `pgdata:/var/lib/postgresql/data`: Cria ou usa um volume chamado "pgdata" e o mapeia para o diretório `/var/lib/postgresql/data` no contêiner.

6. `environment:`: Define variáveis de ambiente para o serviço.

7. `fastzero_app:`: Define o serviço para nossa aplicação.

8. `image: fastzero_app`: Usa a imagem Docker da nossa aplicação.

9. `ports:`: Mapeia portas do contêiner para o host.

   - `"8000:8000"`: Mapeia a porta 8000 do contêiner para a porta 8000 do host.

10. `depends_on:`: Especifica que `fastzero_app` depende de `fastzero_database`. Isto garante que o banco de dados seja iniciado antes da aplicação.

11. `DATABASE_URL: ...`: É uma variável de ambiente que nossa aplicação usará para se conectar ao banco de dados. Aqui, ele se conecta ao serviço `fastzero_database` que definimos anteriormente.

12. `volumes:` (nível superior): Define volumes que podem ser usados pelos serviços.

13. `pgdata:`: Define um volume chamado "pgdata". Este volume é usado para persistir os dados do PostgreSQL entre as execuções do contêiner.

!!! warning "Sobre o docker-compose"
	
	Para usar toda essa funcionalidade maravilhosa do Docker Compose, você precisa tê-lo instalado em seu sistema. Ele não está incluído na instalação padrão do Docker, então lembre-se de instalá-lo separadamente!

Com este arquivo `docker-compose.yml`, você pode iniciar ambos os serviços (aplicação e banco de dados) simultaneamente usando:

```bash
docker-compose up
```

E pará-los com:

```bash
docker-compose down
```

Isso simplifica muito o fluxo de trabalho, pois não há necessidade de gerenciar contêineres individualmente. Além disso, garante que os serviços sejam iniciados na ordem correta e possam se comunicar entre si como esperado.

### Rodando as migrações de forma automática

Um ponto importante em aplicações é garantir que o banco de dados esteja atualizado com as últimas migrações. Para facilitar esse processo, podemos automatizar a execução das migrações toda vez que nosso contêiner for iniciado. **Isso é como garantir que sua cozinha esteja limpa e organizada antes de começar a cozinhar uma refeição**. 

Para implementar isso, precisamos criar um arquivo nomeado `entrypoint.sh`.

```shell
#!/bin/sh

# Roda as migrações
poetry run alembic upgrade head

# Inicia a aplicação
exec "$@"
```

**Explicação do Script**:
- `#!/bin/sh`: Essa é a shebang. Indica que o script deve ser executado usando o shell `/bin/sh`. É uma forma padrão de indicar qual interpretador será utilizado para rodar o script.

- `poetry run alembic upgrade head`: Esta linha executa o comando para rodar as migrações. Estamos utilizando o Alembic, uma ferramenta de migração de banco de dados, para atualizar o banco até a última migração disponível.

- `exec "$@"`: O comando `exec` é usado para executar um comando em seu lugar. `$@` é uma variável especial em scripts shell que se refere a todos os argumentos passados ao script. Portanto, quando o script `entrypoint.sh` é executado com alguns argumentos, eles são passados para o comando `exec` e executados.

**Quando e como isso é executado?**

Quando o contêiner é iniciado, em vez de apenas rodar o comando principal definido no Dockerfile, ele primeiro executa o script de `entrypoint`. Esse script então garante que as migrações sejam rodadas e, posteriormente, executa o comando principal para iniciar a aplicação. A ideia por trás disso é garantir que, antes da aplicação ser iniciada, o banco de dados esteja sempre atualizado com as últimas migrações.

**Para entender melhor**: Pense neste `entrypoint.sh` como uma lista de instruções que o Docker deve seguir toda vez que for iniciar o contêiner, um pouco como um piloto fazendo verificações antes de decolar com um avião. Ele verifica e atualiza o banco de dados primeiro e só depois inicia a aplicação, garantindo que tudo esteja sincronizado e atualizado.

## Commit

Após criar o Dockerfile e testar a imagem Docker, podemos fazer o commit das alterações no Git:

1. Adicione o Dockerfile e quaisquer outros arquivos modificados ao stage do Git com `git add .`
2. Faça o commit das alterações com `git commit -m "Dockerizando nossa aplicação"`
3. Empurre as alterações para o repositório remoto com `git push`

## Conclusão

Dockerizar nossa aplicação FastAPI, junto com o PostgreSQL, nos permite garantir consistência em diferentes ambientes. A combinação de Docker e Docker Compose simplifica o processo de desenvolvimento e implantação. Na próxima aula, vamos aprender como levar nossa aplicação para o próximo nível implantando-a em produção com o Fly.io e também como configurar CI/CD com o GitHub Actions.
