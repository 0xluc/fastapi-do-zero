# [WIP] Dockerizando a nossa aplicação e introduzindo o PostgreSQL

Tópico de manutenção: https://github.com/dunossauro/fastapi-do-zero/issues/38

---
Objetivos da aula:

- Compreender os conceitos básicos do Docker
- Entender como criar uma imagem Docker para a nossa aplicação FastAPI
- Aprender a rodar a aplicação utilizando Docker
- Introduzir o conceito de Docker Compose para gerenciamento de múltiplos contêineres
- Aprender o que é um Dockerfile e sua estrutura
- Entender os benefícios e motivos da mudança de SQLite para PostgreSQL

??? tip "Caso prefira ver a aula em vídeo"
	![type:video](https://www.youtube.com/embed/u31qwQUeGuM)

[Aula :fontawesome-brands-youtube:](#){ .md-button }
[Slides :fontawesome-solid-file-powerpoint:](#){ .md-button }
[Código :fontawesome-solid-code:](https://github.com/dunossauro/fastapi-do-zero/tree/main/codigo_das_aulas/08/){ .md-button }

---

Depois de implementar nosso gerenciador de tarefas na aula anterior, temos uma versão estável da nossa aplicação. Nesta aula, além de aprendermos a "dockerizar" nossa aplicação FastAPI, também abordaremos a migração do banco de dados SQLite para o PostgreSQL.


## O Docker e a nossa aplicação

Docker é uma plataforma aberta que permite automatizar o processo de implantação, escalonamento e operação de aplicações dentro de contêineres. Ele serve para "empacotar" uma aplicação e suas dependências em um contêiner virtual que pode ser executado em qualquer sistema operacional que suporte Docker. Isso facilita a implantação, o desenvolvimento e o compartilhamento de aplicações, além de proporcionar um ambiente isolado e consistente.

### Criando nosso Dockerfile

O Dockerfile é um arquivo de texto que contém todas as instruções para construir uma imagem Docker. Ele define o ambiente de execução, os comandos necessários para preparar o ambiente e o comando a ser executado quando um contêiner é iniciado a partir da imagem.

Aqui está o nosso Dockerfile para a aplicação FastAPI:

```docker
FROM python:3.11-slim
ENV POETRY_VIRTUALENVS_CREATE=false

WORKDIR app/
COPY . .

RUN pip install poetry

RUN poetry config installer.max-workers 10
RUN poetry install --no-interaction --no-ansi

EXPOSE 800
CMD [ "poetry", "run", "uvicorn", "--host", "0.0.0.0", "fast_zero.app:app" ]
```

> Adicionar novos comandos agora que o Dockerfile foi alterado!

Aqui está o que cada linha faz:

1. `FROM python:3.11-slim`: Define a imagem base para nosso contêiner. Estamos usando a versão slim da imagem do Python 3.11, que tem tudo que precisamos para rodar nossa aplicação.
2. `ENV POETRY_VIRTUALENVS_CREATE=false`: Define uma variável de ambiente que diz ao Poetry para não criar um ambiente virtual.
3. `RUN pip install poetry`: Instala o Poetry, nosso gerenciador de pacotes.
4. `WORKDIR app/`: [???]
5. `COPY . .`: Copia todos os arquivos do diretório atual para o contêiner.
6. `RUN poetry config installer.max-workers 10`: Configura o Poetry para usar até 10 workers ao instalar pacotes.
7. `RUN poetry install --no-interaction --no-ansi`: Instala as dependências do nosso projeto sem interação e sem cores no output.
8. `EXPOSE 8000`: Informa ao Docker que o contêiner vai escutar na porta 8000.
9. `CMD [ "poetry", "run", "uvicorn", "--host", "0.0.0.0", "fast_zero.app:app" ]`: Define o comando que será executado quando o contêiner for iniciado.

Vamos entender melhor esse último comando:

- `poetry run` define o comando que será executado dentro do ambiente virtual criado pelo Poetry.
- `uvicorn` é o servidor ASGI que usamos para rodar nossa aplicação.
- `--host` define o host que o servidor vai escutar. Especificamente, `"0.0.0.0"` é um endereço IP que permite que o servidor aceite conexões de qualquer endereço de rede disponível, tornando-o acessível externamente.
- `fast_zero.app:app` define o `<módulo python>:<objeto>` que o servidor vai executar.

### Criando a imagem

Para criar uma imagem Docker a partir do Dockerfile, usamos o comando `docker build`. O comando a seguir cria uma imagem chamada "fast_zero":

```shell title="$ Execução no terminal!"
docker build -t "fast_zero" .
```

Este comando lê o Dockerfile no diretório atual (indicado pelo `.`) e cria uma imagem com a tag "fast_zero", (indicada pelo `-t`).

Vamos então verificar se a imagem foi criada com sucesso usando o comando:

```shell title="$ Execução no terminal!"
docker images
```

Este comando lista todas as imagens Docker disponíveis no seu sistema.

### Executando o container

Para executar o contêiner, usamos o comando `docker run`. Especificamos o nome do contêiner com a flag `--name`, indicamos a imagem que queremos executar e a tag que queremos usar `<nome_da_imagem>:<tag>`. A flag `-p` serve para mapear a porta do host para a porta do contêiner `<porta_do_host>:<porta_do_contêiner>`. Portanto, teremos o seguinte comando:

```shell title="$ Execução no terminal!"
docker run --name fastzeroapp -p 8000:8000 fast_zero:latest
```

Este comando iniciará nossa aplicação dentro de um contêiner Docker, que estará escutando na porta 8000. Para testar se tudo está funcionando corretamente, você pode acessar `http://localhost:8000` em um navegador ou usar um comando como:

```shell title="$ Execução no terminal!"
curl http://localhost:8000
```

???+ danger "Caso você fique preso no terminal"

	Caso você tenha a aplicação travada no terminal e não consiga sair, você pode teclar ++ctrl+"C"++ para parar a execução do container.


### Gerenciando Containers docker

Quando você trabalha com Docker, é importante saber como gerenciar os contêineres. Aqui estão algumas operações básicas para gerenciá-los:

1. **Rodar um contêiner em background**: Se você deseja executar o contêiner em segundo plano para que não ocupe o terminal, pode usar a opção `-d`:

    ```shell title="$ Execução no terminal!"
    docker run -d --name fastzeroapp -p 8000:8000 fast_zero:latest
    ```

2. **Parar um contêiner**: Quando você "para" um contêiner, está essencialmente interrompendo a execução do processo principal do contêiner. Isso significa que o contêiner não está mais ativo, mas ainda existe no sistema, junto com seus dados associados e configuração. Isso permite que você reinicie o contêiner posteriormente, se desejar.

	```shell title="$ Execução no terminal!"
    docker stop fastzeroapp
    ```

3. **Remover um contêiner**: Ao "remover" um contêiner, você está excluindo o contêiner do sistema. Isso significa que todos os dados associados ao contêiner são apagados. Uma vez que um contêiner é removido, você não pode reiniciá-lo; no entanto, você pode sempre criar um novo contêiner a partir da mesma imagem.

	```shell title="$ Execução no terminal!"
    docker rm fastzeroapp
    ```

Ambos os comandos (stop e rm) usam o nome do contêiner que definimos anteriormente com a flag `--name`. É uma boa prática manter a gestão dos seus contêineres, principalmente durante o desenvolvimento, para evitar um uso excessivo de recursos ou conflitos de nomes e portas.

## Introduzindo o postgreSQL

O [PostgreSQL](https://www.postgresql.org/) é um Sistema de Gerenciamento de Banco de Dados Objeto-Relacional (ORDBMS) poderoso e de código aberto. Ele é amplamente utilizado em produção em muitos projetos devido à sua robustez, escalabilidade e conjunto de recursos extensos.

Mudar para um banco de dados como PostgreSQL tem vários benefícios:

- **Escalabilidade**: SQLite não é ideal para aplicações em larga escala ou com grande volume de dados. PostgreSQL foi projetado para lidar com uma grande quantidade de dados e requisições.
- **Concorrência**: Diferentemente do SQLite, que tem limitações para gravações simultâneas, o PostgreSQL suporta múltiplas operações simultâneas.
- **Funcionalidades avançadas**: PostgreSQL vem com várias extensões e funcionalidades que o SQLite pode não oferecer.

Além disso, SQLite tem algumas limitações que podem torná-lo inadequado para produção em alguns casos. Por exemplo, ele não suporta alta concorrência e pode ter problemas de performance com grandes volumes de dados.

!!! note "Nota"
	Embora para o escopo da nossa aplicação e os objetivos de aprendizado o SQLite pudesse ser suficiente, é sempre bom nos prepararmos para cenários de produção real. A adoção de PostgreSQL nos dá uma prévia das práticas do mundo real e garante que nossa aplicação possa escalar sem grandes modificações de infraestrutura.

### Como executar o postgres?

Embora o PostgreSQL seja poderoso, sua instalação direta em uma máquina real pode ser desafiadora e pode resultar em configurações diferentes entre os ambientes de desenvolvimento. Felizmente, podemos utilizar o Docker para resolver esse problema. No Docker Hub, estão disponíveis imagens pré-construídas do PostgreSQL, permitindo-nos executar o PostgreSQL com um único comando. Confira a [imagem oficial do PostgreSQL](https://hub.docker.com/_/postgres).

Para executar um contêiner do PostgreSQL, use o seguinte comando:

```shell title="$ Execução no terminal!"
docker run -d \
    --name app_database \
    -e POSTGRES_USER=app_user \
    -e POSTGRES_DB=app_db \
    -e POSTGRES_PASSWORD=app_password \
    -p 5432:5432 \
    postgres
```

#### Explicando as Flags e Configurações

- **Flag `-e`**:

  Esta flag é usada para definir variáveis de ambiente no contêiner. No contexto do PostgreSQL, essas variáveis são essenciais. Elas configuram o nome de usuário, nome do banco de dados, e senha durante a primeira execução do contêiner. Sem elas, o PostgreSQL pode não iniciar da forma esperada. É uma forma prática de configurar o PostgreSQL sem interagir manualmente ou criar arquivos de configuração.

- **Porta `5432`**:

  O PostgreSQL, por padrão, escuta por conexões na porta `5432`. Mapeando esta porta do contêiner para a mesma porta no host (usando `-p`), fazemos com que o PostgreSQL seja acessível nesta porta na máquina anfitriã, permitindo que outras aplicações se conectem a ele.

!!! warning "Sobre as variáveis"

	Os valores acima (`app_user`, `app_db`, e `app_password`) são padrões genéricos para facilitar a inicialização do PostgreSQL em um ambiente de desenvolvimento. No entanto, é altamente recomendável que você altere esses valores, especialmente `app_password`, para garantir a segurança do seu banco de dados.

#### Volumes e Persistência de Dados

Para garantir a persistência dos dados entre execuções do contêiner, utilizamos volumes. Um volume mapeia um diretório do sistema host para um diretório no contêiner. Isso é crucial para bancos de dados, pois sem um volume, ao remover o contêiner, todos os dados armazenados dentro dele se perderiam.

No PostgreSQL, o diretório padrão para armazenamento de dados é `/var/lib/postgresql/data`. Mapeamos esse diretório para um volume (neste caso "pgdata") em nossa máquina host para garantir a persistência dos dados:

```shell title="$ Execução no terminal!"
docker run -d \
    --name app_database \
    -e POSTGRES_USER=app_user \
    -e POSTGRES_DB=app_db \
    -e POSTGRES_PASSWORD=app_password \
    -v pgdata:/var/lib/postgresql/data \
    -p 5432:5432 \
    postgres
```

O parâmetro do volume é passado ao contêiner usando o parâmetro `-v` Dessa forma, os dados do banco continuarão existindo, mesmo que o contêiner seja reiniciado ou removido.

### Adicionando o suporte ao PostgreSQL na nossa aplicação

Para que o SQLAlchemy suporte o PostgreSQL, precisamos instalar uma dependência chamada `psycopg2-binary`. Este é o adaptador PostgreSQL para Python e é crucial para fazer a comunicação.

Para instalar essa dependência, utilize o seguinte comando:

```shell title="$ Execução no terminal!"
poetry add psycopg2-binary
```

Uma das vantagens do SQLAlchemy enquanto ORM é a flexibilidade. Com apenas algumas alterações mínimas, como a atualização da string de conexão, podemos facilmente transicionar para um banco de dados diferente. Assim, após ajustar o arquivo `.env` com a string de conexão do PostgreSQL, a aplicação deverá operar normalmente, mas desta vez utilizando o PostgreSQL.

Para ajustar a conexão com o PostgreSQL, modifique seu arquivo `.env` para incluir a seguinte string de conexão:

```bash title=".env"
DATABASE_URL="postgresql://app_user:app_password@localhost:5432/app_db"
```

!!! failure "Caso tenha alterado as variáveis de ambiente do contêiner"

	Se você alterou `app_user`, `app_password` ou `app_db` ao inicializar o contêiner PostgreSQL, garanta que esses valores sejam refletidos na string de conexão acima. A palavra `localhost` indica que o banco de dados PostgreSQL está sendo executado na mesma máquina que sua aplicação. Se o banco de dados estiver em uma máquina diferente, substitua `localhost` pelo endereço IP correspondente e, se necessário, ajuste a porta `5432`.


### Executando as migrações

Migrações são como versões para seu banco de dados, permitindo que você atualize sua estrutura de forma ordenada e controlada. Sempre que mudamos de banco de dados, ou até mesmo quando alteramos sua estrutura, as migrações precisam ser executadas para garantir que a base de dados esteja em sincronia com nosso código.

No contexto de contêineres, rodar as migrações se torna ainda mais simples. Quando mudamos de banco de dados, como é o caso de termos saído de um SQLite (por exemplo) para um PostgreSQL, as migrações são essenciais. O motivo é simples: o novo banco de dados não terá a estrutura e os dados do antigo, a menos que migremos. As migrações irão garantir que o novo banco de dados tenha a mesma estrutura e relações que o anterior.

??? warning "Antes de executar o proximo comando"
	Assegure-se de que ambos os contêineres, tanto da aplicação quanto do banco de dados, estejam ativos. O contêiner do banco de dados deve estar rodando para que a aplicação possa se conectar a ele.
	
    Assegure-se de que o contêiner da aplicação esteja ativo. Estamos usando a flag `--network=host` para que o contêiner use a rede do host. Isso pode ser essencial para evitar problemas de conexão, já que não podemos prever como está configurada a rede do computador onde este comando será executado.

    ```bash title="execução no terminal"
    docker run -d --network=host --name fastzeroapp -p 8000:8000 fast_zero:latest
    ```

Para aplicar migrações em um ambiente com contêineres, frequentemente temos comandos específicos associados ao serviço. Vejamos como executar migrações usando o Docker:

```shell title="$ Execução no terminal!"
docker exec -it fastzeroapp poetry run alembic upgrade head
```

O comando `docker exec` é usado para invocar um comando específico dentro de um contêiner em execução. A opção `-it` é uma combinação de `-i` (interativo) e `-t` (pseudo-TTY), que juntas garantem um terminal interativo, permitindo a comunicação direta com o contêiner.

Após executar as migrações, você pode verificar a criação das tabelas utilizando um sistema de gerenciamento de banco de dados. A seguir, apresentamos um exemplo com o Beekeeper Studio:

![Tabelas do PostgreSQL no Beekeeper Studio](assets/10_beekeeper_postgres.png)

**Lembre-se**: Embora as tabelas estejam agora criadas e estruturadas, o banco de dados ainda não contém os dados anteriormente presentes no SQLite ou em qualquer outro banco que você estivesse utilizando antes.


## [WIP] Simplificando nosso fluxo com `docker-compose`

Docker Compose é uma ferramenta que permite definir e gerenciar aplicativos multi-contêiner com Docker. Em termos simples, **é como se você tivesse um maestro conduzindo uma orquestra: em vez de ter que dirigir cada músico (ou contêiner) individualmente, o maestro (ou Docker Compose) garante que todos toquem em harmonia.** Em vez de gerenciar individualmente cada contêiner (como nossa aplicação e o PostgreSQL), podemos definir ambos em um único arquivo `docker-compose.yml` e gerenciá-los simultaneamente com comandos simples.

Ao usar o Docker Compose, nosso objetivo é simplificar o processo de desenvolvimento, tornando mais fácil rodar nossa aplicação e seus serviços dependentes com um único comando.

### Criação do `docker-compose.yml`

```yaml linenums="1" title="docker-compose.yaml"
version: '3'

services:
  fastzero_database:
    image: postgres
    volumes:
      - pgdata:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: app_user
      POSTGRES_DB: app_db
      POSTGRES_PASSWORD: app_password
    ports:
      - "5432:5432"

  fastzero_app:
    image: fastzero_app
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    depends_on:
      - fastzero_database
    environment:
      DATABASE_URL: postgresql://app_user:app_password@fastzero_database:5432/app_db

volumes:
  pgdata:
```


**Explicação linha a linha:**

1. `version: '3'`: Especifica a versão do formato do arquivo Compose. O número '3' é uma das versões mais recentes e amplamente usadas.

2. `services:`: Define os serviços (contêineres) que serão gerenciados.

3. `fastzero_database:`: Define nosso serviço de banco de dados PostgreSQL.

4. `image: postgres`: Usa a imagem oficial do PostgreSQL.

5. `volumes:`: Mapeia volumes para persistência de dados.

   - `pgdata:/var/lib/postgresql/data`: Cria ou usa um volume chamado "pgdata" e o mapeia para o diretório `/var/lib/postgresql/data` no contêiner.

6. `environment:`: Define variáveis de ambiente para o serviço.

7. `fastzero_app:`: Define o serviço para nossa aplicação.

8. `image: fastzero_app`: Usa a imagem Docker da nossa aplicação.

9. `ports:`: Mapeia portas do contêiner para o host.

   - `"8000:8000"`: Mapeia a porta 8000 do contêiner para a porta 8000 do host.

10. `depends_on:`: Especifica que `fastzero_app` depende de `fastzero_database`. Isto garante que o banco de dados seja iniciado antes da aplicação.

11. `DATABASE_URL: ...`: É uma variável de ambiente que nossa aplicação usará para se conectar ao banco de dados. Aqui, ele se conecta ao serviço `fastzero_database` que definimos anteriormente.

12. `volumes:` (nível superior): Define volumes que podem ser usados pelos serviços.

13. `pgdata:`: Define um volume chamado "pgdata". Este volume é usado para persistir os dados do PostgreSQL entre as execuções do contêiner.

!!! warning "Sobre o docker-compose"

	Para usar toda essa funcionalidade maravilhosa do Docker (o compose), você precisa tê-lo instalado em seu sistema. Ele não está incluído na instalação padrão do Docker, então lembre-se de instalá-lo separadamente!

	O guia oficial de instalação pode ser encontrado [aqui](https://docs.docker.com/compose/install/){:target="_blank"}

Com este arquivo `docker-compose.yml`, você pode iniciar ambos os serviços (aplicação e banco de dados) simultaneamente usando:

```bash
docker-compose up
```

E pará-los com:

```bash
docker-compose down
```

Isso simplifica muito o fluxo de trabalho, pois não há necessidade de gerenciar contêineres individualmente. Além disso, garante que os serviços sejam iniciados na ordem correta e possam se comunicar entre si como esperado.

### Rodando as migrações de forma automática

Um ponto importante em aplicações é garantir que o banco de dados esteja atualizado com as últimas migrações. Para facilitar esse processo, podemos automatizar a execução das migrações toda vez que nosso contêiner for iniciado. **Isso é como garantir que sua cozinha esteja limpa e organizada antes de começar a cozinhar uma refeição**.

Para implementar isso, precisamos criar um arquivo nomeado `entrypoint.sh`.

```shell
#!/bin/sh

# Roda as migrações
poetry run alembic upgrade head

# Inicia a aplicação
poetry run uvicorn --host 0.0.0.0 --port 8000 fast_zero.app:app
```

**Explicação do Script**:
- `#!/bin/sh`: Essa é a shebang. Indica que o script deve ser executado usando o shell `/bin/sh`. É uma forma padrão de indicar qual interpretador será utilizado para rodar o script.

- `poetry run alembic upgrade head`: Esta linha executa o comando para rodar as migrações. Estamos utilizando o Alembic, uma ferramenta de migração de banco de dados, para atualizar o banco até a última migração disponível.

- `poetry run uvicorn --host 0.0.0.0 --port 8888 fast_zero.app:app`: Executa a aplicação, como já vimos antes.

**Quando e como isso é executado?**

> Revisar esse parágrafo!

Quando o contêiner é iniciado, em vez de apenas rodar o comando principal definido no Dockerfile, ele primeiro executa o script de `entrypoint`. Esse script então garante que as migrações sejam rodadas e, posteriormente, executa o comando principal para iniciar a aplicação. A ideia por trás disso é garantir que, antes da aplicação ser iniciada, o banco de dados esteja sempre atualizado com as últimas migrações.

**Para entender melhor**: Pense neste `entrypoint.sh` como uma lista de instruções que o Docker deve seguir toda vez que for iniciar o contêiner, um pouco como um piloto fazendo verificações antes de decolar com um avião. Ele verifica e atualiza o banco de dados primeiro e só depois inicia a aplicação, garantindo que tudo esteja sincronizado e atualizado.


> Texto para dizer que iremos adicionar o entrypoint no compose

```yaml title="docker-compose.yaml" linenums="15" hl_lines="3"
  fastzero_app:
    image: fastzero_app
    entrypoint: ./entrypoint.sh
    build:
      context: .
      dockerfile: Dockerfile
```

Para que essa alteração seja executada precisamos iniciar o container novamente. Para garantir que as nossas atualizações sejam consideradas, é sempre bom usar a flag `--build`, que garante que a imagem será gerada novamente a partir do arquivo `Dockerfile`:

```shell title="$ Execução no terminal!"
docker-compose up --build
```

> COLA! 

```shell title="$ Exemplo do resultado no terminal!" hl_lines="1 2 6"
fastzero_app-1  | INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
fastzero_app-1  | INFO  [alembic.runtime.migration] Will assume transactional DDL.
fastzero_app-1  | INFO:     Started server process [10]
fastzero_app-1  | INFO:     Waiting for application startup.
fastzero_app-1  | INFO:     Application startup complete.
fastzero_app-1  | INFO:     Uvicorn running on http://0.0.0.0:8888 (Press CTRL+C to quit)
```

> Dizer que como podemos ver, a migração foi executada antes inicio do Uvicorn ser inicializado

---

??? info "Nota do Will"
	> Adicionar contexto a essa nota. Dizer que as configurações das variáveis do postgres poderiam ser incorporadas no docker-compose.yaml, para que não existisse a necessidade de declarar em texto limpo. Para isso você poderia fazer `.env` [???] - Colocar o exemplo.

	> Caso queria fazer dessa forma, as configurações do pydantic devem mudar no settings, ignorando as variáveis de ambiente não definidas com `extra='ignore'`

    Se for utilizar o .env para a aplicação e para o banco, é necessario configurar o settings.py para ignorar variaveis de ambiente que não são utilizadas pela aplicação https://docs.pydantic.dev/dev/api/config/#pydantic.config.ConfigDict.extra (`model_config = SettingsConfigDict(env_file='.env', env_file_encoding='utf-8', extra='ignore')`)


## [NF] Testes com Docker

> Explicar que precisamos alterar o código e remover as peculiaridades para o sqlite na fixture da sessão

```py title="tests/conftest.py" linenums="1" hl_lines="9 17"
import pytest
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from fast_zero.app import app
from fast_zero.database import get_session
from fast_zero.models import Base
from fast_zero.settings import Settings
from fast_zero.security import get_password_hash
from tests.factories import UserFactory


@pytest.fixture
def session():
    database = 
    engine = create_engine(Settings().DATABASE_URL)
    Session = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    Base.metadata.create_all(engine)
    with Session() as session:
        yield session
        session.rollback()

    Base.metadata.drop_all(engine)
```

> Explicar que esse comando roda os testes da aplicação dentro do docker!

```shell title="$ Execução no terminal!"
docker-compose run --entrypoint="poetry run task test" fastzero_app
```

> Contar o que acontece quando rodamos esse comando, ele inicia o container do banco e roda os testes depois!

## Commit

Após criar o Dockerfile e testar a imagem Docker, podemos fazer o commit das alterações no Git:

1. Adicione o Dockerfile e quaisquer outros arquivos modificados ao stage do Git com `git add .`
2. Faça o commit das alterações com `git commit -m "Dockerizando nossa aplicação"`
3. Empurre as alterações para o repositório remoto com `git push`

## Conclusão

Dockerizar nossa aplicação FastAPI, junto com o PostgreSQL, nos permite garantir consistência em diferentes ambientes. A combinação de Docker e Docker Compose simplifica o processo de desenvolvimento e implantação. Na próxima aula, vamos aprender como levar nossa aplicação para o próximo nível implantando-a em produção com o Fly.io e também como configurar CI/CD com o GitHub Actions.
